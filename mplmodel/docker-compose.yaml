version: '3.8'
services:
  
  spark:
    build:
      context: . 
      dockerfile: model/Dockerfile
    hostname: spark
    container_name: spark
    volumes:
      - ./tmp:/tmp  # Monta ./tmp per mantenere la cache delle dipendenze di Ivy
      - ./model/classificazione.py:/home/spark/classificazione.py
    command: > 
      /opt/spark/bin/spark-submit --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.2,org.elasticsearch:elasticsearch-spark-30_2.12:8.13.4,com.johnsnowlabs.nlp:spark-nlp_2.12:5.3.3  /home/spark/classificazione.py
   

 
 
  elasticsearch:   
    container_name: elasticsearch 
    image: elasticsearch:8.13.4
    ports:
      - 9200:9200
    volumes:
      - ./data_elastic:/usr/share/elasticsearch/data
    environment:
      - node.name=elasticsearch
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    deploy:
      resources:
        limits:
          memory: 1GB
 
        

  
  
  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.4
    container_name: kibana
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
      - 5601:5601
    depends_on:
      elasticsearch:
        condition: service_started
  




volumes:
  data_volume:
  spark-logs:
  